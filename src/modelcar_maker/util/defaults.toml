[meta]
verbosity = 0

[image]
registry = "quay.io"
repository = "jharmison/models"
push = true
cleanup = false
skip_if_exists = true

[models]
cleanup = false
default = [
    "BAAI/bge-m3",
    "Qwen/Qwen3-14B",
    "Qwen/Qwen3-14B-FP8",
    "Qwen/Qwen3-8B",
    "Qwen/Qwen3-8B-FP8",
    "RedHatAI/Llama-3.1-8B-Instruct-speculator.eagle3",
    "RedHatAI/Llama-3.2-3B-Instruct-FP8",
    "RedHatAI/Llama-3.2-3B-Instruct-quantized.w8a8",
    "RedHatAI/Llama-3.3-70B-Instruct-quantized.w4a16",
    "RedHatAI/Llama-3.3-70B-Instruct-speculator.eagle3",
    "RedHatAI/Llama-4-Scout-17B-16E-Instruct-quantized.w4a16",
    "RedHatAI/Mistral-Small-3.1-24B-Instruct-2503-FP8-dynamic",
    "RedHatAI/NVIDIA-Nemotron-Nano-9B-v2-FP8-dynamic",
    "RedHatAI/Qwen3-14B-speculator.eagle3",
    "RedHatAI/Qwen3-32B-speculator.eagle3",
    "RedHatAI/Qwen3-8B-speculator.eagle3",
    "RedHatAI/Voxtral-Mini-3B-2507-FP8-dynamic",
    "RedHatAI/gpt-oss-120b",
    "RedHatAI/gpt-oss-20b",
    "RedHatAI/granite-3.1-8b-instruct-FP8-dynamic",
    "RedHatAI/granite-3.1-8b-instruct-quantized.w8a8",
    "ibm-granite/granite-3.2-8b-instruct",
    "ibm-granite/granite-3.3-8b-instruct",
    "ibm-granite/granite-4.0-h-micro",
    "ibm-granite/granite-4.0-h-small",
    "ibm-granite/granite-4.0-h-tiny",
    "ibm-granite/granite-4.0-micro",
    "ibm-granite/granite-8b-code-instruct-128k",
    "intfloat/multilingual-e5-large",
    "intfloat/multilingual-e5-large-instruct",
    "meta-llama/Llama-3.1-8B-Instruct",
    "meta-llama/Llama-3.2-3B-Instruct",
    "meta-llama/Llama-3.3-70B-Instruct",
    "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "nvidia/NVIDIA-Nemotron-Nano-9B-v2"
]
